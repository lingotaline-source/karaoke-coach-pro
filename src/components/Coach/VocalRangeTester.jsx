import { useState, useRef, useEffect } from 'react'
import { PitchDetector } from 'pitchy'
import './VocalRangeTester.css'

function VocalRangeTester({ onClose }) {
    const [step, setStep] = useState('intro') // intro, recording_low, recording_high, result
    const [detectedFreq, setDetectedFreq] = useState(0)
    const [detectedNote, setDetectedNote] = useState('')
    const [lowNote, setLowNote] = useState(null)
    const [highNote, setHighNote] = useState(null)
    const [audioLevel, setAudioLevel] = useState(0)

    const audioContextRef = useRef(null)
    const analyserRef = useRef(null)
    const mediaStreamRef = useRef(null)
    const pitchDetectorRef = useRef(null)
    const animationFrameRef = useRef(null)
    const stableNoteCount = useRef(0)
    const lastNoteRef = useRef(null)

    const noteNames = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']

    const frequencyToNote = (frequency) => {
        const noteNum = 12 * (Math.log(frequency / 440) / Math.log(2))
        const roundedNote = Math.round(noteNum) + 69
        const octave = Math.floor(roundedNote / 12) - 1
        const noteName = noteNames[roundedNote % 12]
        return { name: noteName, octave, fullName: `${noteName}${octave}`, frequency }
    }

    const startListening = async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
            mediaStreamRef.current = stream
            audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)()
            const source = audioContextRef.current.createMediaStreamSource(stream)
            analyserRef.current = audioContextRef.current.createAnalyser()
            analyserRef.current.fftSize = 2048
            source.connect(analyserRef.current)
            pitchDetectorRef.current = PitchDetector.forFloat32Array(analyserRef.current.fftSize)
            detectPitch()
        } catch (error) {
            console.error("Erreur micro:", error)
        }
    }

    const stopListening = () => {
        if (animationFrameRef.current) cancelAnimationFrame(animationFrameRef.current)
        if (mediaStreamRef.current) mediaStreamRef.current.getTracks().forEach(track => track.stop())
        if (audioContextRef.current) audioContextRef.current.close()
    }

    useEffect(() => {
        if (step === 'recording_low' || step === 'recording_high') {
            startListening()
        } else {
            stopListening()
        }
        return () => stopListening()
    }, [step])

    const detectPitch = () => {
        if (!analyserRef.current) return

        const buffer = new Float32Array(analyserRef.current.fftSize)
        analyserRef.current.getFloatTimeDomainData(buffer)
        const [frequency, clarity] = pitchDetectorRef.current.findPitch(buffer, audioContextRef.current.sampleRate)

        // Audio level
        let sum = 0
        for (let i = 0; i < buffer.length; i++) sum += buffer[i] * buffer[i]
        const rms = Math.sqrt(sum / buffer.length)
        setAudioLevel(Math.min(100, rms * 500))

        if (clarity > 0.9 && frequency > 50 && frequency < 1500) {
            const note = frequencyToNote(frequency)
            setDetectedFreq(frequency)
            setDetectedNote(note.fullName)

            // Stabilisation simple
            if (lastNoteRef.current === note.fullName) {
                stableNoteCount.current++
            } else {
                stableNoteCount.current = 0
                lastNoteRef.current = note.fullName
            }
        } else {
            stableNoteCount.current = 0
        }

        animationFrameRef.current = requestAnimationFrame(detectPitch)
    }

    const captureLowNote = () => {
        if (detectedFreq > 0) {
            setLowNote({ freq: detectedFreq, note: detectedNote })
            setStep('recording_high')
        }
    }

    const captureHighNote = () => {
        if (detectedFreq > 0) {
            setHighNote({ freq: detectedFreq, note: detectedNote })
            setStep('result')
        }
    }

    const determineVocalType = () => {
        if (!lowNote || !highNote) return "Inconnu"

        // Logique simplifi√©e bas√©e sur le centre de la tessiture ou les extr√™mes
        // Moyenne des fr√©quences pour estimer le centre
        const centerFreq = (lowNote.freq + highNote.freq) / 2

        // Classification approximative bas√©e sur les fr√©quences centrales typiques
        if (centerFreq > 500) return "Soprano"
        if (centerFreq > 400) return "Mezzo-Soprano"
        if (centerFreq > 300) return "Alto / Contre-t√©nor"
        if (centerFreq > 220) return "T√©nor"
        if (centerFreq > 150) return "Baryton"
        return "Basse"
    }

    const getVocalDescription = (type) => {
        const descriptions = {
            "Soprano": "La voix la plus aigu√´, capable d'atteindre des notes tr√®s hautes avec brillance.",
            "Mezzo-Soprano": "Une voix polyvalente, avec des graves chauds et des aigus puissants.",
            "Alto / Contre-t√©nor": "Une voix grave et riche chez les femmes, ou tr√®s aigu√´ chez les hommes.",
            "T√©nor": "La voix masculine la plus aigu√´, souvent h√©ro√Øque et brillante.",
            "Baryton": "La voix masculine moyenne, tr√®s courante, alliant chaleur et puissance.",
            "Basse": "La voix la plus grave, profonde et r√©sonnante."
        }
        return descriptions[type] || ""
    }

    const vocalType = step === 'result' ? determineVocalType() : ''

    return (
        <div className="vocal-range-overlay">
            <div className="vocal-range-modal glass-effect">
                <button className="close-btn" onClick={onClose}>√ó</button>

                <h2>üé§ Test de Tessiture</h2>

                {step === 'intro' && (
                    <div className="step-content">
                        <p>D√©couvrons votre type de voix ! Nous allons identifier votre note la plus grave et votre note la plus aigu√´.</p>
                        <button className="btn-primary" onClick={() => setStep('recording_low')}>Commencer</button>
                    </div>
                )}

                {(step === 'recording_low' || step === 'recording_high') && (
                    <div className="step-content">
                        <h3>
                            {step === 'recording_low' ? "Chantez votre note la plus GRAVE ‚¨áÔ∏è" : "Chantez votre note la plus AIGU√ã ‚¨ÜÔ∏è"}
                        </h3>
                        <p className="instruction">Tenez la note quelques secondes...</p>

                        <div className="visualizer">
                            <div className="note-display">{detectedNote || "..."}</div>
                            <div className="freq-display">{Math.round(detectedFreq)} Hz</div>
                            <div className="level-bar-container">
                                <div className="level-bar" style={{ width: `${audioLevel}%` }}></div>
                            </div>
                        </div>

                        <button
                            className="btn-primary capture-btn"
                            onClick={step === 'recording_low' ? captureLowNote : captureHighNote}
                            disabled={!detectedNote}
                        >
                            C'est ma note !
                        </button>
                    </div>
                )}

                {step === 'result' && (
                    <div className="step-content result-content">
                        <h3>Votre tessiture estim√©e :</h3>
                        <div className="vocal-type-badge">{vocalType}</div>
                        <p className="vocal-desc">{getVocalDescription(vocalType)}</p>

                        <div className="range-details">
                            <div className="range-item">
                                <span>Grave :</span>
                                <strong>{lowNote.note}</strong>
                            </div>
                            <div className="range-arrow">‚ÜîÔ∏è</div>
                            <div className="range-item">
                                <span>Aigu :</span>
                                <strong>{highNote.note}</strong>
                            </div>
                        </div>

                        <button className="btn-secondary" onClick={() => setStep('intro')}>Recommencer</button>
                    </div>
                )}
            </div>
        </div>
    )
}

export default VocalRangeTester
